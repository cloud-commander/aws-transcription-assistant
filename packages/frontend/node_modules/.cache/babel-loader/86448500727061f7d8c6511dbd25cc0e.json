{"ast":null,"code":"/**\n * Convert IBM json to draftJS\n * see `sample` folder for example of input and output as well as `example-usage.js`\n *\n */\nimport generateEntitiesRanges from '../generate-entities-ranges/index.js';\n\nconst ibmToDraft = ibmJson => {\n  // helper function to normalise IBM words at line level\n  const normalizeTimeStampsToWords = timestamps => {\n    return timestamps.map(ibmWord => {\n      return {\n        text: ibmWord[0],\n        start: ibmWord[1],\n        end: ibmWord[2]\n      };\n    });\n  }; //\n\n\n  const normalizeIBMWordsList = ibmResults => {\n    const normalisedResults = [];\n    ibmResults.forEach(result => {\n      // nested array to keep paragraph segmentation same as IBM lines\n      normalisedResults.push(normalizeTimeStampsToWords(result.alternatives[0].timestamps)); // TODO: can be revisited - as separate PR by flattening the array like this\n      // normalisedResults = normalisedResults.concact(normalizeTimeStampsToWords(result.alternatives[0].timestamps));\n      // addSpeakersToWords function would need adjusting as would be dealing with a 1D array instead of 2D\n      // if edge case, like in example file, that there's one speaker recognised through all of speaker segemtnation info\n      // could break into paragraph when is over a minute? at end of IBM line?\n      // or punctuation, altho IBM does not seem to provide punctuation?\n    });\n    return normalisedResults;\n  }; // TODO: could be separate file\n\n\n  const findSpeakerSegmentForWord = (word, speakerSegments) => {\n    const tmpSegment = speakerSegments.find(seg => {\n      const segStart = seg.from;\n      const segEnd = seg.to;\n      return word.start === segStart && word.end === segEnd;\n    }); // if find doesn't find any matches it returns an undefined\n\n    if (tmpSegment === undefined) {\n      // covering edge case orphan word not belonging to any segments\n      // adding UKN speaker label\n      return 'UKN';\n    } else {\n      // find returns the first element that matches the criteria\n      return `S_${tmpSegment.speaker}`;\n    }\n  }; // add speakers to words\n\n\n  const addSpeakersToWords = (ibmWords, ibmSpeakers) => {\n    return ibmWords.map(lines => {\n      return lines.map(word => {\n        word.speaker = findSpeakerSegmentForWord(word, ibmSpeakers);\n        return word;\n      });\n    });\n  };\n\n  const ibmNormalisedWordsToDraftJs = ibmNormalisedWordsWithSpeakers => {\n    const draftJsParagraphsResults = [];\n    ibmNormalisedWordsWithSpeakers.forEach(ibmParagraph => {\n      const draftJsContentBlockParagraph = {\n        text: ibmParagraph.map(word => {\n          return word.text;\n        }).join(' '),\n        type: 'paragraph',\n        data: {\n          // Assuming each paragraph in IBM line is the same\n          // for context it just seems like the IBM data structure gives you word level speakers,\n          // but also gives you \"lines\" so assuming each word in a line has the same speaker.\n          speaker: ibmParagraph[0].speaker,\n          words: ibmParagraph,\n          start: ibmParagraph[0].start\n        },\n        // the entities as ranges are each word in the space-joined text,\n        // so it needs to be compute for each the offset from the beginning of the paragraph and the length\n        entityRanges: generateEntitiesRanges(ibmParagraph, 'text') // wordAttributeName\n\n      };\n      draftJsParagraphsResults.push(draftJsContentBlockParagraph);\n    });\n    return draftJsParagraphsResults;\n  };\n\n  const normalisedWords = normalizeIBMWordsList(ibmJson.results[0].results); // TODO: nested array of words, to keep some sort of paragraphs, in case there's only one speaker\n  // can be refactored/optimised later\n\n  const ibmNormalisedWordsWithSpeakers = addSpeakersToWords(normalisedWords, ibmJson.results[0].speaker_labels);\n  const ibmDratJs = ibmNormalisedWordsToDraftJs(ibmNormalisedWordsWithSpeakers);\n  return ibmDratJs;\n};\n\nexport default ibmToDraft;","map":{"version":3,"sources":["/home/cmsgdiav/Desktop/React Projects/aws-transcription-assistant-05/packages/frontend/src/packages/stt-adapters/ibm/index.js"],"names":["generateEntitiesRanges","ibmToDraft","ibmJson","normalizeTimeStampsToWords","timestamps","map","ibmWord","text","start","end","normalizeIBMWordsList","ibmResults","normalisedResults","forEach","result","push","alternatives","findSpeakerSegmentForWord","word","speakerSegments","tmpSegment","find","seg","segStart","from","segEnd","to","undefined","speaker","addSpeakersToWords","ibmWords","ibmSpeakers","lines","ibmNormalisedWordsToDraftJs","ibmNormalisedWordsWithSpeakers","draftJsParagraphsResults","ibmParagraph","draftJsContentBlockParagraph","join","type","data","words","entityRanges","normalisedWords","results","speaker_labels","ibmDratJs"],"mappings":"AAAA;;;;;AAKA,OAAOA,sBAAP,MAAmC,sCAAnC;;AAEA,MAAMC,UAAU,GAAGC,OAAO,IAAI;AAC5B;AACA,QAAMC,0BAA0B,GAAGC,UAAU,IAAI;AAC/C,WAAOA,UAAU,CAACC,GAAX,CAAeC,OAAO,IAAI;AAC/B,aAAO;AACLC,QAAAA,IAAI,EAAED,OAAO,CAAC,CAAD,CADR;AAELE,QAAAA,KAAK,EAAEF,OAAO,CAAC,CAAD,CAFT;AAGLG,QAAAA,GAAG,EAAEH,OAAO,CAAC,CAAD;AAHP,OAAP;AAKD,KANM,CAAP;AAOD,GARD,CAF4B,CAY5B;;;AACA,QAAMI,qBAAqB,GAAGC,UAAU,IAAI;AAC1C,UAAMC,iBAAiB,GAAG,EAA1B;AACAD,IAAAA,UAAU,CAACE,OAAX,CAAmBC,MAAM,IAAI;AAC3B;AACAF,MAAAA,iBAAiB,CAACG,IAAlB,CAAuBZ,0BAA0B,CAACW,MAAM,CAACE,YAAP,CAAoB,CAApB,EAAuBZ,UAAxB,CAAjD,EAF2B,CAG3B;AACA;AACA;AACA;AACA;AACA;AACD,KATD;AAWA,WAAOQ,iBAAP;AACD,GAdD,CAb4B,CA6B5B;;;AACA,QAAMK,yBAAyB,GAAG,CAACC,IAAD,EAAOC,eAAP,KAA2B;AAC3D,UAAMC,UAAU,GAAGD,eAAe,CAACE,IAAhB,CAAqBC,GAAG,IAAI;AAC7C,YAAMC,QAAQ,GAAGD,GAAG,CAACE,IAArB;AACA,YAAMC,MAAM,GAAGH,GAAG,CAACI,EAAnB;AAEA,aAASR,IAAI,CAACV,KAAL,KAAee,QAAhB,IAA8BL,IAAI,CAACT,GAAL,KAAagB,MAAnD;AACD,KALkB,CAAnB,CAD2D,CAO3D;;AACA,QAAIL,UAAU,KAAKO,SAAnB,EAA8B;AAC5B;AACA;AACA,aAAO,KAAP;AACD,KAJD,MAIO;AACL;AACA,aAAQ,KAAKP,UAAU,CAACQ,OAAS,EAAjC;AACD;AACF,GAhBD,CA9B4B,CA+C5B;;;AACA,QAAMC,kBAAkB,GAAG,CAACC,QAAD,EAAWC,WAAX,KAA2B;AACpD,WAAOD,QAAQ,CAACzB,GAAT,CAAa2B,KAAK,IAAI;AAC3B,aAAOA,KAAK,CAAC3B,GAAN,CAAUa,IAAI,IAAI;AAEvBA,QAAAA,IAAI,CAACU,OAAL,GAAeX,yBAAyB,CAACC,IAAD,EAAOa,WAAP,CAAxC;AAEA,eAAOb,IAAP;AACD,OALM,CAAP;AAMD,KAPM,CAAP;AAQD,GATD;;AAWA,QAAMe,2BAA2B,GAAIC,8BAAD,IAAoC;AACtE,UAAMC,wBAAwB,GAAG,EAAjC;AACAD,IAAAA,8BAA8B,CAACrB,OAA/B,CAAwCuB,YAAD,IAAkB;AACvD,YAAMC,4BAA4B,GAAG;AACnC9B,QAAAA,IAAI,EAAE6B,YAAY,CAAC/B,GAAb,CAAkBa,IAAD,IAAU;AAAC,iBAAOA,IAAI,CAACX,IAAZ;AAAkB,SAA9C,EAAgD+B,IAAhD,CAAqD,GAArD,CAD6B;AAEnCC,QAAAA,IAAI,EAAE,WAF6B;AAGnCC,QAAAA,IAAI,EAAE;AACJ;AACA;AACA;AACAZ,UAAAA,OAAO,EAAEQ,YAAY,CAAC,CAAD,CAAZ,CAAgBR,OAJrB;AAKJa,UAAAA,KAAK,EAAEL,YALH;AAMJ5B,UAAAA,KAAK,EAAE4B,YAAY,CAAC,CAAD,CAAZ,CAAgB5B;AANnB,SAH6B;AAWnC;AACA;AACAkC,QAAAA,YAAY,EAAE1C,sBAAsB,CAACoC,YAAD,EAAe,MAAf,CAbD,CAayB;;AAbzB,OAArC;AAeAD,MAAAA,wBAAwB,CAACpB,IAAzB,CAA8BsB,4BAA9B;AACD,KAjBD;AAmBA,WAAOF,wBAAP;AACD,GAtBD;;AAwBA,QAAMQ,eAAe,GAAGjC,qBAAqB,CAACR,OAAO,CAAC0C,OAAR,CAAgB,CAAhB,EAAmBA,OAApB,CAA7C,CAnF4B,CAoF5B;AACA;;AACA,QAAMV,8BAA8B,GAAGL,kBAAkB,CAACc,eAAD,EAAkBzC,OAAO,CAAC0C,OAAR,CAAgB,CAAhB,EAAmBC,cAArC,CAAzD;AACA,QAAMC,SAAS,GAAGb,2BAA2B,CAACC,8BAAD,CAA7C;AAEA,SAAOY,SAAP;AACD,CA1FD;;AA4FA,eAAe7C,UAAf","sourcesContent":["/**\n * Convert IBM json to draftJS\n * see `sample` folder for example of input and output as well as `example-usage.js`\n *\n */\nimport generateEntitiesRanges from '../generate-entities-ranges/index.js';\n\nconst ibmToDraft = ibmJson => {\n  // helper function to normalise IBM words at line level\n  const normalizeTimeStampsToWords = timestamps => {\n    return timestamps.map(ibmWord => {\n      return {\n        text: ibmWord[0],\n        start: ibmWord[1],\n        end: ibmWord[2]\n      };\n    });\n  };\n\n  //\n  const normalizeIBMWordsList = ibmResults => {\n    const normalisedResults = [];\n    ibmResults.forEach(result => {\n      // nested array to keep paragraph segmentation same as IBM lines\n      normalisedResults.push(normalizeTimeStampsToWords(result.alternatives[0].timestamps));\n      // TODO: can be revisited - as separate PR by flattening the array like this\n      // normalisedResults = normalisedResults.concact(normalizeTimeStampsToWords(result.alternatives[0].timestamps));\n      // addSpeakersToWords function would need adjusting as would be dealing with a 1D array instead of 2D\n      // if edge case, like in example file, that there's one speaker recognised through all of speaker segemtnation info\n      // could break into paragraph when is over a minute? at end of IBM line?\n      // or punctuation, altho IBM does not seem to provide punctuation?\n    });\n\n    return normalisedResults;\n  };\n\n  // TODO: could be separate file\n  const findSpeakerSegmentForWord = (word, speakerSegments) => {\n    const tmpSegment = speakerSegments.find(seg => {\n      const segStart = seg.from;\n      const segEnd = seg.to;\n\n      return ((word.start === segStart) && (word.end === segEnd));\n    });\n    // if find doesn't find any matches it returns an undefined\n    if (tmpSegment === undefined) {\n      // covering edge case orphan word not belonging to any segments\n      // adding UKN speaker label\n      return 'UKN';\n    } else {\n      // find returns the first element that matches the criteria\n      return `S_${ tmpSegment.speaker }`;\n    }\n  };\n  // add speakers to words\n  const addSpeakersToWords = (ibmWords, ibmSpeakers) => {\n    return ibmWords.map(lines => {\n      return lines.map(word => {\n\n        word.speaker = findSpeakerSegmentForWord(word, ibmSpeakers);\n\n        return word;\n      });\n    });\n  };\n\n  const ibmNormalisedWordsToDraftJs = (ibmNormalisedWordsWithSpeakers) => {\n    const draftJsParagraphsResults = [];\n    ibmNormalisedWordsWithSpeakers.forEach((ibmParagraph) => {\n      const draftJsContentBlockParagraph = {\n        text: ibmParagraph.map((word) => {return word.text;}).join(' '),\n        type: 'paragraph',\n        data: {\n          // Assuming each paragraph in IBM line is the same\n          // for context it just seems like the IBM data structure gives you word level speakers,\n          // but also gives you \"lines\" so assuming each word in a line has the same speaker.\n          speaker: ibmParagraph[0].speaker,\n          words: ibmParagraph,\n          start: ibmParagraph[0].start\n        },\n        // the entities as ranges are each word in the space-joined text,\n        // so it needs to be compute for each the offset from the beginning of the paragraph and the length\n        entityRanges: generateEntitiesRanges(ibmParagraph, 'text'), // wordAttributeName\n      };\n      draftJsParagraphsResults.push(draftJsContentBlockParagraph);\n    });\n\n    return draftJsParagraphsResults;\n  };\n\n  const normalisedWords = normalizeIBMWordsList(ibmJson.results[0].results);\n  // TODO: nested array of words, to keep some sort of paragraphs, in case there's only one speaker\n  // can be refactored/optimised later\n  const ibmNormalisedWordsWithSpeakers = addSpeakersToWords(normalisedWords, ibmJson.results[0].speaker_labels);\n  const ibmDratJs = ibmNormalisedWordsToDraftJs(ibmNormalisedWordsWithSpeakers);\n\n  return ibmDratJs;\n};\n\nexport default ibmToDraft;\n"]},"metadata":{},"sourceType":"module"}